{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd422a04-86e2-4715-97f5-fd703c9f6e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This notebook demonstrates the architecture and parameter settings of the MentalAId model. \n",
    "# Due to stochastic initialization, training results may slightly vary. \n",
    "# To use the trained MentalAId, please refer to the model directory in the root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdc7b1c-ba27-4000-8f96-f7687b1a542e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:06.179002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cce37da-17d7-4ada-9c56-7cb391464c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/data/home/lmx/psy_test/v1_20241016/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1782bc-356e-4129-b6ee-c8fc30c65df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 2 Logical gpus\n",
      "(7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:07.407476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-05-07 10:45:07.421695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.421951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:5b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.421975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:07.424313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:07.424356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-07 10:45:07.426900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-07 10:45:07.427210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-07 10:45:07.429835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-07 10:45:07.431074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-07 10:45:07.436347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-07 10:45:07.437195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2025-05-07 10:45:07.438298: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-07 10:45:07.445964: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2700000000 Hz\n",
      "2025-05-07 10:45:07.446177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x697d430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-07 10:45:07.446207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-07 10:45:07.677424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x69fcab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-07 10:45:07.677505: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-05-07 10:45:07.677526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-05-07 10:45:07.678644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.678866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:5b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.678900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:07.678921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:07.678932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-07 10:45:07.678944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-07 10:45:07.678956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-07 10:45:07.678967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-07 10:45:07.678978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-07 10:45:07.678989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-07 10:45:07.679672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2025-05-07 10:45:07.679704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:08.582268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-05-07 10:45:08.582313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2025-05-07 10:45:08.582331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2025-05-07 10:45:08.582336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2025-05-07 10:45:08.583212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:25:00.0, compute capability: 7.0)\n",
      "2025-05-07 10:45:08.583970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 1024 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:5b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_USE_FRONTEND'] = '1'\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = '0'\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    \n",
    "tf.config.set_soft_device_placement = False\n",
    "tf.config.experimental.set_memory_growth = True\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"gpus:\", gpus)\n",
    " \n",
    "\n",
    "if gpus:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), len(logical_gpus), 'Logical gpus')\n",
    "    \n",
    "### set background seed\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.experimental.numpy.random.seed(seed)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "x_train = np.load('./data/x_train.npy',allow_pickle=True)\n",
    "y_train = np.load('./data/y_train.npy',allow_pickle=True)\n",
    "print(x_train[0].shape)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_train = x_train.astype('float32') \n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60d86b3-8f68-4fdb-bd57-e68f1ac81928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sex_train = pd.read_csv('./data/data_clean.csv', index_col='Unnamed: 0')['Gender']\n",
    "\n",
    "### set sex female=0 male=1 \n",
    "sex_train = sex_train.replace(['F','女'],0)\n",
    "sex_train = sex_train.replace(['M','男'],1)\n",
    "\n",
    "sex_train.value_counts()\n",
    "\n",
    "sex_train = np.array(sex_train).astype(np.float32)\n",
    "\n",
    "age_train = pd.read_csv('./data/data_clean.csv', index_col='Unnamed: 0')['Age']\n",
    "\n",
    "age_train = np.array(age_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33678832-7df4-4cfa-b742-fbf9bbf4161d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MentalAId with sex & gender "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789af48-b6f1-4619-a637-edbec6959670",
   "metadata": {
    "tags": []
   },
   "source": [
    "## network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da7fbd7-8360-4c4c-b7e7-53b5b999a462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define bottleneck\n",
    "class BottleNeck(tf.keras.layers.Layer):\n",
    "    def __init__(self, growth_rate, drop_rate):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=4 * growth_rate,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=growth_rate,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=drop_rate)\n",
    "        \n",
    "        self.listLayers = [self.bn1,\n",
    "                           tf.keras.layers.Activation(\"relu\"),\n",
    "                           self.conv1,\n",
    "                           self.bn2,\n",
    "                           tf.keras.layers.Activation(\"relu\"),\n",
    "                           self.conv2,\n",
    "                           self.dropout]\n",
    "\n",
    "    def call(self, x):\n",
    "        tf.random.set_seed(seed)\n",
    "        y = x\n",
    "        for layer in self.listLayers.layers:\n",
    "            y = layer(y)\n",
    "        y = tf.keras.layers.concatenate([x,y], axis=-1)\n",
    "        return y\n",
    "\n",
    "# define dense block\n",
    "class DenseBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, growth_rate, drop_rate=0.5):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.growth_rate = growth_rate\n",
    "        self.drop_rate = drop_rate\n",
    "        self.listLayers = []\n",
    "        for _ in range(num_layers):\n",
    "            self.listLayers.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n",
    "\n",
    "    def call(self, x):\n",
    "        tf.random.set_seed(seed)\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# define transition\n",
    "class TransitionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=out_channels,\n",
    "                                           kernel_size=(1, 1),\n",
    "                                           strides=1,\n",
    "                                           padding=\"same\")\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              padding=\"same\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        tf.random.set_seed(seed)\n",
    "        x = self.bn(inputs)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# define dense net\n",
    "class DenseNet(tf.keras.Model):\n",
    "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=num_init_features,\n",
    "                                           kernel_size=(3, 3),\n",
    "                                           strides=1,\n",
    "                                           input_shape = (7,7,1),\n",
    "                                           padding=\"same\")\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.num_channels = num_init_features\n",
    "        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[0]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[1]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "                \n",
    "        # MLP layers for age and gender (this module is added)\n",
    "        self.age_dense = tf.keras.layers.Dense(units=16, activation='relu', name='age_dense')\n",
    "        self.gender_dense = tf.keras.layers.Dense(units=16, activation='relu', name='gender_dense')\n",
    "        \n",
    "        # fc\n",
    "        self.fc = tf.keras.layers.Dense(units=2,\n",
    "                                        activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs should now include image, age, gender\n",
    "        image_input, age_input, gender_input = inputs\n",
    "        \n",
    "        # tf.random.set_seed(seed)\n",
    "        x = self.conv(image_input)\n",
    "        x = self.bn(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        x = self.dense_block_1(x)\n",
    "        x = self.transition_1(x)\n",
    "        x = self.dense_block_2(x)\n",
    "        x = self.transition_2(x)\n",
    "        x = self.dense_block_3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        ## Processing age and gender inputs through their respective dense layers               \n",
    "        age_features = self.age_dense(age_input)\n",
    "        gender_features = self.gender_dense(gender_input)\n",
    "        \n",
    "        # Concatenate image features with age and gender features\n",
    "        x = tf.concat([x, age_features, gender_features], axis=-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f97ebf-7c29-45c4-9d7e-7d3d428f5d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc105de-0d5e-41bc-8919-50e78c5acbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterTraining(object):\n",
    "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, \n",
    "                 drop_rate, no_epochs_1, no_epochs_2, lr_1, lr_2, n_bootstrap=1000):\n",
    "        self.num_init_features = num_init_features\n",
    "        self.growth_rate = growth_rate\n",
    "        self.block_layers = block_layers\n",
    "        self.compression_rate = compression_rate\n",
    "        self.drop_rate = drop_rate\n",
    "        self.no_epochs_1 = no_epochs_1\n",
    "        self.no_epochs_2 = no_epochs_2\n",
    "        self.lr_1 = lr_1\n",
    "        self.lr_2 = lr_2\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "\n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate metrics with robust error handling\"\"\"\n",
    "        try:\n",
    "            # Handle input formats\n",
    "            if len(y_pred.shape) == 2 and y_pred.shape[1] > 1:\n",
    "                y_pred_class = np.argmax(y_pred, axis=1)\n",
    "                y_pred_proba = y_pred[:, 1] if y_pred.shape[1] == 2 else y_pred\n",
    "            else:\n",
    "                y_pred_class = y_pred\n",
    "                y_pred_proba = y_pred\n",
    "\n",
    "            if len(y_true.shape) == 2 and y_true.shape[1] > 1:\n",
    "                y_true_class = np.argmax(y_true, axis=1)\n",
    "            else:\n",
    "                y_true_class = y_true\n",
    "\n",
    "            # Calculate metrics\n",
    "            precision = metrics.precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            recall = metrics.recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            mcc = metrics.matthews_corrcoef(y_true_class, y_pred_class)\n",
    "            cm = metrics.confusion_matrix(y_true_class, y_pred_class)\n",
    "            \n",
    "            # Handle specificity calculation\n",
    "            specificity = 0.0\n",
    "            if cm.shape == (2, 2):\n",
    "                specificity = cm[0,0]/(cm[0,0]+cm[0,1]) if (cm[0,0]+cm[0,1]) > 0 else 0\n",
    "            \n",
    "            accuracy = metrics.accuracy_score(y_true_class, y_pred_class)\n",
    "            \n",
    "            # Handle AUC calculation\n",
    "            auc = 0.5  # Default value for degenerate cases\n",
    "            if len(np.unique(y_true_class)) >= 2:\n",
    "                try:\n",
    "                    auc = metrics.roc_auc_score(y_true_class, y_pred_proba)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'specificity': specificity,\n",
    "                'mcc': mcc,\n",
    "                'auc': auc\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics: {e}\")\n",
    "            return {\n",
    "                'accuracy': np.nan,\n",
    "                'precision': np.nan,\n",
    "                'recall': np.nan,\n",
    "                'specificity': np.nan,\n",
    "                'mcc': np.nan,\n",
    "                'auc': np.nan\n",
    "            }\n",
    "\n",
    "    def _bootstrap_ci(self, y_true, y_pred, n_bootstrap=1000):\n",
    "        \"\"\"Calculate bootstrap CIs with robust sampling\"\"\"\n",
    "        boot_stats = {\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'specificity': [],\n",
    "            'mcc': [],\n",
    "            'auc': []\n",
    "        }\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            try:\n",
    "                # Resample with replacement\n",
    "                indices = resample(np.arange(len(y_true)))\n",
    "                y_true_sample = y_true[indices]\n",
    "                y_pred_sample = y_pred[indices]\n",
    "                \n",
    "                # Skip if only one class in sample\n",
    "                if len(np.unique(np.argmax(y_true_sample, axis=1))) < 2:\n",
    "                    continue\n",
    "                \n",
    "                metrics_dict = self._calculate_metrics(y_true_sample, y_pred_sample)\n",
    "                \n",
    "                # Only append valid metrics\n",
    "                for key in boot_stats:\n",
    "                    if not np.isnan(metrics_dict[key]):\n",
    "                        boot_stats[key].append(metrics_dict[key])\n",
    "            except Exception as e:\n",
    "                print(f\"Bootstrap sampling failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate CIs only if we have enough samples\n",
    "        ci_dict = {}\n",
    "        for key in boot_stats:\n",
    "            if len(boot_stats[key]) >= 30:  # Minimum samples for reliable CI\n",
    "                ci_dict[f'{key}_ci'] = (\n",
    "                    np.percentile(boot_stats[key], 2.5),\n",
    "                    np.percentile(boot_stats[key], 97.5)\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Warning: Not enough valid samples for {key} CI (n={len(boot_stats[key])})\")\n",
    "                ci_dict[f'{key}_ci'] = (np.nan, np.nan)\n",
    "        \n",
    "        return ci_dict\n",
    "\n",
    "    def train(self, x_train, y_train, age_train, sex_train, kfold, seed, EarlyStop):\n",
    "        \"\"\"Main training method with cross-validation\"\"\"\n",
    "        # Initialize metric containers\n",
    "        cv_metrics = {\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'specificity': [],\n",
    "            'mcc': [],\n",
    "            'auc': []\n",
    "        }\n",
    "        \n",
    "        # Store all predictions for final bootstrap\n",
    "        all_val_preds = []\n",
    "        all_val_true = []\n",
    "        \n",
    "        fold_no = 1\n",
    "        for train_idx, val_idx in kfold.split(x_train, y_train):\n",
    "            print(f\"\\n--- Processing Fold {fold_no}/{kfold.n_splits} ---\")\n",
    "            \n",
    "            # Model initialization\n",
    "            model = DenseNet(\n",
    "                num_init_features=self.num_init_features[0],\n",
    "                growth_rate=self.growth_rate[0],\n",
    "                block_layers=self.block_layers,\n",
    "                compression_rate=self.compression_rate[0],\n",
    "                drop_rate=self.drop_rate[0]\n",
    "            )\n",
    "            \n",
    "            # First training phase\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr_1),\n",
    "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                [x_train[train_idx], age_train[train_idx], sex_train[train_idx]], \n",
    "                y_train[train_idx],\n",
    "                batch_size=256,\n",
    "                epochs=self.no_epochs_1,\n",
    "                validation_data=([x_train[val_idx], age_train[val_idx], sex_train[val_idx]], y_train[val_idx]),\n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStop]\n",
    "            )\n",
    "            \n",
    "            # Second training phase\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr_2),\n",
    "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                [x_train[train_idx], age_train[train_idx], sex_train[train_idx]], \n",
    "                y_train[train_idx],\n",
    "                batch_size=256,\n",
    "                epochs=self.no_epochs_2,\n",
    "                validation_data=([x_train[val_idx], age_train[val_idx], sex_train[val_idx]], y_train[val_idx]),\n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStop]\n",
    "            )\n",
    "            \n",
    "            # Validation predictions\n",
    "            y_pred_val = model.predict([x_train[val_idx], age_train[val_idx], sex_train[val_idx]])\n",
    "            y_val = y_train[val_idx]\n",
    "            \n",
    "            # Store predictions for final bootstrap\n",
    "            all_val_preds.append(y_pred_val)\n",
    "            all_val_true.append(y_val)\n",
    "            \n",
    "            # Calculate fold metrics\n",
    "            y_pred_class = np.argmax(y_pred_val, axis=1)\n",
    "            y_true_class = np.argmax(y_val, axis=1)\n",
    "            metrics_dict = self._calculate_metrics(y_true_class, y_pred_class)\n",
    "            \n",
    "            for key in cv_metrics:\n",
    "                cv_metrics[key].append(metrics_dict[key])\n",
    "            \n",
    "            fold_no += 1\n",
    "        \n",
    "        # Concatenate all validation results\n",
    "        all_val_preds = np.concatenate(all_val_preds)\n",
    "        all_val_true = np.concatenate(all_val_true)\n",
    "        all_val_true_class = np.argmax(all_val_true, axis=1)\n",
    "        \n",
    "        # Calculate cross-validation stats\n",
    "        cv_stats = {}\n",
    "        for key in cv_metrics:\n",
    "            cv_stats[f'{key}_mean'] = np.nanmean(cv_metrics[key])\n",
    "            cv_stats[f'{key}_std'] = np.nanstd(cv_metrics[key])\n",
    "        \n",
    "        # Calculate bootstrap CIs\n",
    "        print(\"\\nCalculating bootstrap confidence intervals...\")\n",
    "        bootstrap_cis = self._bootstrap_ci(all_val_true, all_val_preds, self.n_bootstrap)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = {\n",
    "            'Metric': ['Accuracy', 'Precision', 'Recall (Sensitivity)', 'Specificity', 'MCC', 'AUC'],\n",
    "            'Mean': [\n",
    "                cv_stats['accuracy_mean'],\n",
    "                cv_stats['precision_mean'],\n",
    "                cv_stats['recall_mean'],\n",
    "                cv_stats['specificity_mean'],\n",
    "                cv_stats['mcc_mean'],\n",
    "                cv_stats['auc_mean']\n",
    "            ],\n",
    "            'Std': [\n",
    "                cv_stats['accuracy_std'],\n",
    "                cv_stats['precision_std'],\n",
    "                cv_stats['recall_std'],\n",
    "                cv_stats['specificity_std'],\n",
    "                cv_stats['mcc_std'],\n",
    "                cv_stats['auc_std']\n",
    "            ],\n",
    "            '95% CI': [\n",
    "                f\"({bootstrap_cis['accuracy_ci'][0]:.3f}, {bootstrap_cis['accuracy_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['precision_ci'][0]:.3f}, {bootstrap_cis['precision_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['recall_ci'][0]:.3f}, {bootstrap_cis['recall_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['specificity_ci'][0]:.3f}, {bootstrap_cis['specificity_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['mcc_ci'][0]:.3f}, {bootstrap_cis['mcc_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['auc_ci'][0]:.3f}, {bootstrap_cis['auc_ci'][1]:.3f})\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Format output\n",
    "        def format_value(x):\n",
    "            if isinstance(x, str):\n",
    "                return x\n",
    "            return f\"{x:.1%}\" if x <= 1 else f\"{x:.3f}\"\n",
    "        \n",
    "        for col in ['Mean', 'Std']:\n",
    "            results_df[col] = results_df[col].apply(format_value)\n",
    "        \n",
    "        # Save results\n",
    "        dir = os.path.join(\"/data/home/lmx/psy_test/v2_20250425/\", \"github\")\n",
    "        os.makedirs(seed_dir, exist_ok=True)\n",
    "        model.save(dir)\n",
    "                \n",
    "        return {\n",
    "            'accuracy': cv_stats['accuracy_mean'],\n",
    "            'precision': cv_stats['precision_mean'],\n",
    "            'recall': cv_stats['recall_mean'],\n",
    "            'specificity': cv_stats['specificity_mean'],\n",
    "            'mcc': cv_stats['mcc_mean'],\n",
    "            'auc': cv_stats['auc_mean'],\n",
    "            'results_df': results_df\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8371b373-da0c-4cea-b955-46720977525c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Fold 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:09.811353: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-05-07 10:45:12.389229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:12.619321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Fold 2/10 ---\n",
      "\n",
      "--- Processing Fold 3/10 ---\n",
      "\n",
      "--- Processing Fold 4/10 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     kfold \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mnum_folds, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mPT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mage_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mage_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43msex_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msex_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEarlyStop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEarlyStop\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Training Completed ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 170\u001b[0m, in \u001b[0;36mParameterTraining.train\u001b[0;34m(self, x_train, y_train, age_train, sex_train, kfold, seed, EarlyStop)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Second training phase\u001b[39;00m\n\u001b[1;32m    164\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    165\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    166\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_2),\n\u001b[1;32m    167\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mAUC(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    168\u001b[0m )\n\u001b[0;32m--> 170\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msex_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_epochs_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msex_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Validation predictions\u001b[39;00m\n\u001b[1;32m    181\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([x_train[val_idx], age_train[val_idx], sex_train[val_idx]])\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow-2.4.0/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============ Main Execution ============ \n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    num_folds = 10\n",
    "    batch_size = 256\n",
    "    no_epochs = 200\n",
    "\n",
    "    num_init_features = [32]\n",
    "    growth_rate = [8]\n",
    "    block_layers = [3, 4, 3]\n",
    "    compression_rate = [0.5]\n",
    "    drop_rate = [0.3]\n",
    "    no_epochs_1 = 10\n",
    "    no_epochs_2 = 200\n",
    "    lr_1 = 1e-3\n",
    "    lr_2 = 1e-4\n",
    "\n",
    "    EarlyStop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=20,\n",
    "        min_delta=0,\n",
    "        mode='auto',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Initialize training class\n",
    "    PT = ParameterTraining(\n",
    "        num_init_features=num_init_features,\n",
    "        growth_rate=growth_rate,\n",
    "        block_layers=block_layers,\n",
    "        compression_rate=compression_rate,\n",
    "        drop_rate=drop_rate,\n",
    "        no_epochs_1=no_epochs_1,\n",
    "        no_epochs_2=no_epochs_2,\n",
    "        lr_1=lr_1,\n",
    "        lr_2=lr_2,\n",
    "        n_bootstrap=1000  # Number of bootstrap samples\n",
    "    )\n",
    "\n",
    "    # Shuffle data (assuming x_train, y_train, etc. are defined)\n",
    "    shuffle_idx = np.random.permutation(np.arange(len(x_train)))\n",
    "    x_train = x_train[shuffle_idx]\n",
    "    y_train = y_train[shuffle_idx]\n",
    "    age_train = age_train[shuffle_idx]\n",
    "    sex_train = sex_train[shuffle_idx]\n",
    "\n",
    "    # Initialize KFold\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Run training\n",
    "    results = PT.train(\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        age_train=age_train,\n",
    "        sex_train=sex_train,\n",
    "        kfold=kfold,\n",
    "        seed=seed,\n",
    "        EarlyStop=EarlyStop\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\n=== Training Completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f927f-7654-45be-b954-83d0249de26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.4",
   "language": "python",
   "name": "tensorflow-2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

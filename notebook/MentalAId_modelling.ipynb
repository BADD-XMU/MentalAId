{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdc7b1c-ba27-4000-8f96-f7687b1a542e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:06.179002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cce37da-17d7-4ada-9c56-7cb391464c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/data/home/lmx/psy_test/v1_20241016/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1782bc-356e-4129-b6ee-c8fc30c65df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 2 Logical gpus\n",
      "(7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:07.407476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-05-07 10:45:07.421695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.421951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:5b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.421975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:07.424313: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:07.424356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-07 10:45:07.426900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-07 10:45:07.427210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-07 10:45:07.429835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-07 10:45:07.431074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-07 10:45:07.436347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-07 10:45:07.437195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2025-05-07 10:45:07.438298: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-07 10:45:07.445964: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2700000000 Hz\n",
      "2025-05-07 10:45:07.446177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x697d430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-07 10:45:07.446207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-07 10:45:07.677424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x69fcab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-07 10:45:07.677505: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-05-07 10:45:07.677526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2025-05-07 10:45:07.678644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:25:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.678866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:5b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2025-05-07 10:45:07.678900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:07.678921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:07.678932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-05-07 10:45:07.678944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-05-07 10:45:07.678956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-05-07 10:45:07.678967: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-05-07 10:45:07.678978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-05-07 10:45:07.678989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-05-07 10:45:07.679672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2025-05-07 10:45:07.679704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-05-07 10:45:08.582268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-05-07 10:45:08.582313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2025-05-07 10:45:08.582331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y \n",
      "2025-05-07 10:45:08.582336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N \n",
      "2025-05-07 10:45:08.583212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:25:00.0, compute capability: 7.0)\n",
      "2025-05-07 10:45:08.583970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 1024 MB memory) -> physical GPU (device: 1, name: Tesla V100-PCIE-32GB, pci bus id: 0000:5b:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_USE_FRONTEND'] = '1'\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = '0'\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    \n",
    "tf.config.set_soft_device_placement = False\n",
    "tf.config.experimental.set_memory_growth = True\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"gpus:\", gpus)\n",
    " \n",
    "\n",
    "if gpus:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[1], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), len(logical_gpus), 'Logical gpus')\n",
    "    \n",
    "### set background seed\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.experimental.numpy.random.seed(seed)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "x_train = np.load('./data/x_train.npy',allow_pickle=True)\n",
    "y_train = np.load('./data/y_train.npy',allow_pickle=True)\n",
    "print(x_train[0].shape)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_train = x_train.astype('float32') \n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60d86b3-8f68-4fdb-bd57-e68f1ac81928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sex_train = pd.read_csv('./data/data_clean.csv', index_col='Unnamed: 0')['Gender']\n",
    "\n",
    "### set sex female=0 male=1 \n",
    "sex_train = sex_train.replace(['F','女'],0)\n",
    "sex_train = sex_train.replace(['M','男'],1)\n",
    "\n",
    "sex_train.value_counts()\n",
    "\n",
    "sex_train = np.array(sex_train).astype(np.float32)\n",
    "\n",
    "age_train = pd.read_csv('./data/data_clean.csv', index_col='Unnamed: 0')['Age']\n",
    "\n",
    "age_train = np.array(age_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8a65a-5f6f-47c8-8863-8dfcdc2106f0",
   "metadata": {},
   "source": [
    "## import external validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c351b3e9-6f81-4076-bb47-358b8065cf08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7, 7)\n",
      "(3047, 7, 7)\n",
      "(5641, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# FEP\n",
    "x_FEP = np.load('/data/home/lmx/psy_test/v1_20241016/data/x_FEP.npy',allow_pickle=True)\n",
    "y_FEP = np.load('/data/home/lmx/psy_test/v1_20241016/data/y_FEP.npy',allow_pickle=True)\n",
    "print(x_FEP.shape)\n",
    "x_FEP = np.expand_dims(x_FEP, -1)\n",
    "x_FEP = x_FEP.astype('float32') \n",
    "\n",
    "# outlier\n",
    "x_outlier = np.load('/data/home/lmx/psy_test/v1_20241016/data/x_outlier.npy',allow_pickle=True)\n",
    "y_outlier = np.load('/data/home/lmx/psy_test/v1_20241016/data/y_outlier.npy',allow_pickle=True)\n",
    "print(x_outlier.shape)\n",
    "x_outlier = np.expand_dims(x_outlier, -1)\n",
    "x_outlier = x_outlier.astype('float32')\n",
    "\n",
    "# incomplete records\n",
    "x_incomplete = np.load('/data/home/lmx/psy_test/v1_20241016/data/x_incomplete.npy',allow_pickle=True)\n",
    "y_incomplete = np.load('/data/home/lmx/psy_test/v1_20241016/data/y_incomplete.npy',allow_pickle=True)\n",
    "print(x_incomplete.shape)\n",
    "x_incomplete = np.expand_dims(x_incomplete, -1)\n",
    "x_incomplete = x_incomplete.astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe06172-105b-4f12-a50d-dc6aa5a80411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_FEP = pd.read_csv('./data/data_FEP.csv', index_col='Unnamed: 0')['Age']\n",
    "sex_FEP = pd.read_csv('./data/data_FEP.csv', index_col='Unnamed: 0')['Gender']\n",
    "age_FEP = age_FEP.reset_index(drop=True)\n",
    "sex_FEP = sex_FEP.reset_index(drop=True)\n",
    "\n",
    "### set sex female=0 male=1\n",
    "index_sex_FEP = sex_FEP[sex_FEP.isin(['F', 'M'])].index\n",
    "index_sex_FEP.shape\n",
    "sex_FEP = sex_FEP[index_sex_FEP]\n",
    "age_FEP = age_FEP[index_sex_FEP]\n",
    "\n",
    "sex_FEP = sex_FEP.replace(['F'],0)\n",
    "sex_FEP = sex_FEP.replace(['M'],1)\n",
    "\n",
    "sex_FEP = np.array(sex_FEP).astype('float32') \n",
    "age_FEP = np.array(age_FEP).astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a69c08-9554-46d7-b559-af7971582169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_outlier = pd.read_csv('./data/data_outliers.csv', index_col='Unnamed: 0')['Age']\n",
    "sex_outlier = pd.read_csv('./data/data_outliers.csv', index_col='Unnamed: 0')['Gender']\n",
    "\n",
    "### set sex female=0 male=1 \n",
    "sex_outlier = sex_outlier.replace(['F','女'],0)\n",
    "sex_outlier = sex_outlier.replace(['M','男'],1)\n",
    "\n",
    "sex_outlier = np.array(sex_outlier).astype('float32') \n",
    "age_outlier = np.array(age_outlier).astype('float32') \n",
    "\n",
    "age_NA = pd.read_csv('./data/data_NA.csv', index_col='Unnamed: 0')['Age']\n",
    "sex_NA = pd.read_csv('./data/data_NA.csv', index_col='Unnamed: 0')['Gender']\n",
    "age_NA = age_NA.reset_index(drop=True)\n",
    "sex_NA = sex_NA.reset_index(drop=True)\n",
    "\n",
    "sex_NA = sex_NA.replace(['F','女'],0)\n",
    "sex_NA = sex_NA.replace(['M','男'],1)\n",
    "\n",
    "sex_NA = np.array(sex_NA).astype('float32') \n",
    "age_NA = np.array(age_NA).astype('float32') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33678832-7df4-4cfa-b742-fbf9bbf4161d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MentalAId with sex & gender "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789af48-b6f1-4619-a637-edbec6959670",
   "metadata": {
    "tags": []
   },
   "source": [
    "## network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da7fbd7-8360-4c4c-b7e7-53b5b999a462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define bottleneck\n",
    "class BottleNeck(tf.keras.layers.Layer):\n",
    "    def __init__(self, growth_rate, drop_rate):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=4 * growth_rate,\n",
    "                                            kernel_size=(1, 1),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=growth_rate,\n",
    "                                            kernel_size=(3, 3),\n",
    "                                            strides=1,\n",
    "                                            padding=\"same\")\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=drop_rate)\n",
    "        \n",
    "        self.listLayers = [self.bn1,\n",
    "                           tf.keras.layers.Activation(\"relu\"),\n",
    "                           self.conv1,\n",
    "                           self.bn2,\n",
    "                           tf.keras.layers.Activation(\"relu\"),\n",
    "                           self.conv2,\n",
    "                           self.dropout]\n",
    "\n",
    "    def call(self, x):\n",
    "        tf.random.set_seed(seed)\n",
    "        y = x\n",
    "        for layer in self.listLayers.layers:\n",
    "            y = layer(y)\n",
    "        y = tf.keras.layers.concatenate([x,y], axis=-1)\n",
    "        return y\n",
    "\n",
    "# define dense block\n",
    "class DenseBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, growth_rate, drop_rate=0.5):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.growth_rate = growth_rate\n",
    "        self.drop_rate = drop_rate\n",
    "        self.listLayers = []\n",
    "        for _ in range(num_layers):\n",
    "            self.listLayers.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n",
    "\n",
    "    def call(self, x):\n",
    "        tf.random.set_seed(seed)\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# define transition\n",
    "class TransitionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=out_channels,\n",
    "                                           kernel_size=(1, 1),\n",
    "                                           strides=1,\n",
    "                                           padding=\"same\")\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n",
    "                                              strides=2,\n",
    "                                              padding=\"same\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        tf.random.set_seed(seed)\n",
    "        x = self.bn(inputs)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# define dense net\n",
    "class DenseNet(tf.keras.Model):\n",
    "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=num_init_features,\n",
    "                                           kernel_size=(3, 3),\n",
    "                                           strides=1,\n",
    "                                           input_shape = (7,7,1),\n",
    "                                           padding=\"same\")\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.num_channels = num_init_features\n",
    "        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[0]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        self.num_channels += growth_rate * block_layers[1]\n",
    "        self.num_channels = compression_rate * self.num_channels\n",
    "        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n",
    "        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "        \n",
    "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "                \n",
    "        # MLP layers for age and gender (this module is added)\n",
    "        self.age_dense = tf.keras.layers.Dense(units=16, activation='relu', name='age_dense')\n",
    "        self.gender_dense = tf.keras.layers.Dense(units=16, activation='relu', name='gender_dense')\n",
    "        \n",
    "        # fc\n",
    "        self.fc = tf.keras.layers.Dense(units=2,\n",
    "                                        activation=tf.keras.activations.softmax)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs should now include image, age, gender\n",
    "        image_input, age_input, gender_input = inputs\n",
    "        \n",
    "        # tf.random.set_seed(seed)\n",
    "        x = self.conv(image_input)\n",
    "        x = self.bn(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        x = self.dense_block_1(x)\n",
    "        x = self.transition_1(x)\n",
    "        x = self.dense_block_2(x)\n",
    "        x = self.transition_2(x)\n",
    "        x = self.dense_block_3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        ## Processing age and gender inputs through their respective dense layers               \n",
    "        age_features = self.age_dense(age_input)\n",
    "        gender_features = self.gender_dense(gender_input)\n",
    "        \n",
    "        # Concatenate image features with age and gender features\n",
    "        x = tf.concat([x, age_features, gender_features], axis=-1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f97ebf-7c29-45c4-9d7e-7d3d428f5d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc105de-0d5e-41bc-8919-50e78c5acbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterTraining(object):\n",
    "    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, \n",
    "                 drop_rate, no_epochs_1, no_epochs_2, lr_1, lr_2, n_bootstrap=1000):\n",
    "        self.num_init_features = num_init_features\n",
    "        self.growth_rate = growth_rate\n",
    "        self.block_layers = block_layers\n",
    "        self.compression_rate = compression_rate\n",
    "        self.drop_rate = drop_rate\n",
    "        self.no_epochs_1 = no_epochs_1\n",
    "        self.no_epochs_2 = no_epochs_2\n",
    "        self.lr_1 = lr_1\n",
    "        self.lr_2 = lr_2\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "\n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate metrics with robust error handling\"\"\"\n",
    "        try:\n",
    "            # Handle input formats\n",
    "            if len(y_pred.shape) == 2 and y_pred.shape[1] > 1:\n",
    "                y_pred_class = np.argmax(y_pred, axis=1)\n",
    "                y_pred_proba = y_pred[:, 1] if y_pred.shape[1] == 2 else y_pred\n",
    "            else:\n",
    "                y_pred_class = y_pred\n",
    "                y_pred_proba = y_pred\n",
    "\n",
    "            if len(y_true.shape) == 2 and y_true.shape[1] > 1:\n",
    "                y_true_class = np.argmax(y_true, axis=1)\n",
    "            else:\n",
    "                y_true_class = y_true\n",
    "\n",
    "            # Calculate metrics\n",
    "            precision = metrics.precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            recall = metrics.recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "            mcc = metrics.matthews_corrcoef(y_true_class, y_pred_class)\n",
    "            cm = metrics.confusion_matrix(y_true_class, y_pred_class)\n",
    "            \n",
    "            # Handle specificity calculation\n",
    "            specificity = 0.0\n",
    "            if cm.shape == (2, 2):\n",
    "                specificity = cm[0,0]/(cm[0,0]+cm[0,1]) if (cm[0,0]+cm[0,1]) > 0 else 0\n",
    "            \n",
    "            accuracy = metrics.accuracy_score(y_true_class, y_pred_class)\n",
    "            \n",
    "            # Handle AUC calculation\n",
    "            auc = 0.5  # Default value for degenerate cases\n",
    "            if len(np.unique(y_true_class)) >= 2:\n",
    "                try:\n",
    "                    auc = metrics.roc_auc_score(y_true_class, y_pred_proba)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'specificity': specificity,\n",
    "                'mcc': mcc,\n",
    "                'auc': auc\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics: {e}\")\n",
    "            return {\n",
    "                'accuracy': np.nan,\n",
    "                'precision': np.nan,\n",
    "                'recall': np.nan,\n",
    "                'specificity': np.nan,\n",
    "                'mcc': np.nan,\n",
    "                'auc': np.nan\n",
    "            }\n",
    "\n",
    "    def _bootstrap_ci(self, y_true, y_pred, n_bootstrap=1000):\n",
    "        \"\"\"Calculate bootstrap CIs with robust sampling\"\"\"\n",
    "        boot_stats = {\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'specificity': [],\n",
    "            'mcc': [],\n",
    "            'auc': []\n",
    "        }\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            try:\n",
    "                # Resample with replacement\n",
    "                indices = resample(np.arange(len(y_true)))\n",
    "                y_true_sample = y_true[indices]\n",
    "                y_pred_sample = y_pred[indices]\n",
    "                \n",
    "                # Skip if only one class in sample\n",
    "                if len(np.unique(np.argmax(y_true_sample, axis=1))) < 2:\n",
    "                    continue\n",
    "                \n",
    "                metrics_dict = self._calculate_metrics(y_true_sample, y_pred_sample)\n",
    "                \n",
    "                # Only append valid metrics\n",
    "                for key in boot_stats:\n",
    "                    if not np.isnan(metrics_dict[key]):\n",
    "                        boot_stats[key].append(metrics_dict[key])\n",
    "            except Exception as e:\n",
    "                print(f\"Bootstrap sampling failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Calculate CIs only if we have enough samples\n",
    "        ci_dict = {}\n",
    "        for key in boot_stats:\n",
    "            if len(boot_stats[key]) >= 30:  # Minimum samples for reliable CI\n",
    "                ci_dict[f'{key}_ci'] = (\n",
    "                    np.percentile(boot_stats[key], 2.5),\n",
    "                    np.percentile(boot_stats[key], 97.5)\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Warning: Not enough valid samples for {key} CI (n={len(boot_stats[key])})\")\n",
    "                ci_dict[f'{key}_ci'] = (np.nan, np.nan)\n",
    "        \n",
    "        return ci_dict\n",
    "\n",
    "    def train(self, x_train, y_train, age_train, sex_train, kfold, seed, EarlyStop):\n",
    "        \"\"\"Main training method with cross-validation\"\"\"\n",
    "        # Initialize metric containers\n",
    "        cv_metrics = {\n",
    "            'accuracy': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'specificity': [],\n",
    "            'mcc': [],\n",
    "            'auc': []\n",
    "        }\n",
    "        \n",
    "        # Store all predictions for final bootstrap\n",
    "        all_val_preds = []\n",
    "        all_val_true = []\n",
    "        \n",
    "        fold_no = 1\n",
    "        for train_idx, val_idx in kfold.split(x_train, y_train):\n",
    "            print(f\"\\n--- Processing Fold {fold_no}/{kfold.n_splits} ---\")\n",
    "            \n",
    "            # Model initialization\n",
    "            model = DenseNet(\n",
    "                num_init_features=self.num_init_features[0],\n",
    "                growth_rate=self.growth_rate[0],\n",
    "                block_layers=self.block_layers,\n",
    "                compression_rate=self.compression_rate[0],\n",
    "                drop_rate=self.drop_rate[0]\n",
    "            )\n",
    "            \n",
    "            # First training phase\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr_1),\n",
    "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                [x_train[train_idx], age_train[train_idx], sex_train[train_idx]], \n",
    "                y_train[train_idx],\n",
    "                batch_size=256,\n",
    "                epochs=self.no_epochs_1,\n",
    "                validation_data=([x_train[val_idx], age_train[val_idx], sex_train[val_idx]], y_train[val_idx]),\n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStop]\n",
    "            )\n",
    "            \n",
    "            # Second training phase\n",
    "            model.compile(\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr_2),\n",
    "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            \n",
    "            history = model.fit(\n",
    "                [x_train[train_idx], age_train[train_idx], sex_train[train_idx]], \n",
    "                y_train[train_idx],\n",
    "                batch_size=256,\n",
    "                epochs=self.no_epochs_2,\n",
    "                validation_data=([x_train[val_idx], age_train[val_idx], sex_train[val_idx]], y_train[val_idx]),\n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStop]\n",
    "            )\n",
    "            \n",
    "            # Validation predictions\n",
    "            y_pred_val = model.predict([x_train[val_idx], age_train[val_idx], sex_train[val_idx]])\n",
    "            y_val = y_train[val_idx]\n",
    "            \n",
    "            # Store predictions for final bootstrap\n",
    "            all_val_preds.append(y_pred_val)\n",
    "            all_val_true.append(y_val)\n",
    "            \n",
    "            # Calculate fold metrics\n",
    "            y_pred_class = np.argmax(y_pred_val, axis=1)\n",
    "            y_true_class = np.argmax(y_val, axis=1)\n",
    "            metrics_dict = self._calculate_metrics(y_true_class, y_pred_class)\n",
    "            \n",
    "            for key in cv_metrics:\n",
    "                cv_metrics[key].append(metrics_dict[key])\n",
    "            \n",
    "            fold_no += 1\n",
    "        \n",
    "        # Concatenate all validation results\n",
    "        all_val_preds = np.concatenate(all_val_preds)\n",
    "        all_val_true = np.concatenate(all_val_true)\n",
    "        all_val_true_class = np.argmax(all_val_true, axis=1)\n",
    "        \n",
    "        # Calculate cross-validation stats\n",
    "        cv_stats = {}\n",
    "        for key in cv_metrics:\n",
    "            cv_stats[f'{key}_mean'] = np.nanmean(cv_metrics[key])\n",
    "            cv_stats[f'{key}_std'] = np.nanstd(cv_metrics[key])\n",
    "        \n",
    "        # Calculate bootstrap CIs\n",
    "        print(\"\\nCalculating bootstrap confidence intervals...\")\n",
    "        bootstrap_cis = self._bootstrap_ci(all_val_true, all_val_preds, self.n_bootstrap)\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = {\n",
    "            'Metric': ['Accuracy', 'Precision', 'Recall (Sensitivity)', 'Specificity', 'MCC', 'AUC'],\n",
    "            'Mean': [\n",
    "                cv_stats['accuracy_mean'],\n",
    "                cv_stats['precision_mean'],\n",
    "                cv_stats['recall_mean'],\n",
    "                cv_stats['specificity_mean'],\n",
    "                cv_stats['mcc_mean'],\n",
    "                cv_stats['auc_mean']\n",
    "            ],\n",
    "            'Std': [\n",
    "                cv_stats['accuracy_std'],\n",
    "                cv_stats['precision_std'],\n",
    "                cv_stats['recall_std'],\n",
    "                cv_stats['specificity_std'],\n",
    "                cv_stats['mcc_std'],\n",
    "                cv_stats['auc_std']\n",
    "            ],\n",
    "            '95% CI': [\n",
    "                f\"({bootstrap_cis['accuracy_ci'][0]:.3f}, {bootstrap_cis['accuracy_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['precision_ci'][0]:.3f}, {bootstrap_cis['precision_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['recall_ci'][0]:.3f}, {bootstrap_cis['recall_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['specificity_ci'][0]:.3f}, {bootstrap_cis['specificity_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['mcc_ci'][0]:.3f}, {bootstrap_cis['mcc_ci'][1]:.3f})\",\n",
    "                f\"({bootstrap_cis['auc_ci'][0]:.3f}, {bootstrap_cis['auc_ci'][1]:.3f})\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Format output\n",
    "        def format_value(x):\n",
    "            if isinstance(x, str):\n",
    "                return x\n",
    "            return f\"{x:.1%}\" if x <= 1 else f\"{x:.3f}\"\n",
    "        \n",
    "        for col in ['Mean', 'Std']:\n",
    "            results_df[col] = results_df[col].apply(format_value)\n",
    "        \n",
    "        # Save results\n",
    "        dir = os.path.join(\"/data/home/lmx/psy_test/v2_20250425/\", \"github\")\n",
    "        os.makedirs(seed_dir, exist_ok=True)\n",
    "        model.save(dir)\n",
    "                \n",
    "        return {\n",
    "            'accuracy': cv_stats['accuracy_mean'],\n",
    "            'precision': cv_stats['precision_mean'],\n",
    "            'recall': cv_stats['recall_mean'],\n",
    "            'specificity': cv_stats['specificity_mean'],\n",
    "            'mcc': cv_stats['mcc_mean'],\n",
    "            'auc': cv_stats['auc_mean'],\n",
    "            'results_df': results_df\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371b373-da0c-4cea-b955-46720977525c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Fold 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 10:45:09.811353: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-05-07 10:45:12.389229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-05-07 10:45:12.619321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Fold 2/10 ---\n"
     ]
    }
   ],
   "source": [
    "# ============ Main Execution ============ \n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    num_folds = 10\n",
    "    batch_size = 256\n",
    "    no_epochs = 200\n",
    "\n",
    "    num_init_features = [32]\n",
    "    growth_rate = [8]\n",
    "    block_layers = [3, 4, 3]\n",
    "    compression_rate = [0.5]\n",
    "    drop_rate = [0.3]\n",
    "    no_epochs_1 = 10\n",
    "    no_epochs_2 = 200\n",
    "    lr_1 = 1e-3\n",
    "    lr_2 = 1e-4\n",
    "\n",
    "    EarlyStop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=20,\n",
    "        min_delta=0,\n",
    "        mode='auto',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Initialize training class\n",
    "    PT = ParameterTraining(\n",
    "        num_init_features=num_init_features,\n",
    "        growth_rate=growth_rate,\n",
    "        block_layers=block_layers,\n",
    "        compression_rate=compression_rate,\n",
    "        drop_rate=drop_rate,\n",
    "        no_epochs_1=no_epochs_1,\n",
    "        no_epochs_2=no_epochs_2,\n",
    "        lr_1=lr_1,\n",
    "        lr_2=lr_2,\n",
    "        n_bootstrap=1000  # Number of bootstrap samples\n",
    "    )\n",
    "\n",
    "    # Shuffle data (assuming x_train, y_train, etc. are defined)\n",
    "    shuffle_idx = np.random.permutation(np.arange(len(x_train)))\n",
    "    x_train = x_train[shuffle_idx]\n",
    "    y_train = y_train[shuffle_idx]\n",
    "    age_train = age_train[shuffle_idx]\n",
    "    sex_train = sex_train[shuffle_idx]\n",
    "\n",
    "    # Initialize KFold\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    # Run training\n",
    "    results = PT.train(\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        age_train=age_train,\n",
    "        sex_train=sex_train,\n",
    "        kfold=kfold,\n",
    "        seed=seed,\n",
    "        EarlyStop=EarlyStop\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\n=== Training Completed ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f927f-7654-45be-b954-83d0249de26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.4",
   "language": "python",
   "name": "tensorflow-2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
